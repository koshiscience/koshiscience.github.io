<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator><link href="https://koshiscience.github.io/pages/koshiscience/feed.xml" rel="self" type="application/atom+xml" /><link href="https://koshiscience.github.io/pages/koshiscience/" rel="alternate" type="text/html" /><updated>2022-05-27T08:55:25+00:00</updated><id>https://koshiscience.github.io/pages/koshiscience/feed.xml</id><title type="html">高志中学校サイエンス部</title><subtitle>福井県立高志中学校にある部活、サイエンス部のホームページ</subtitle><entry><title type="html">一年生のwebサイト作品</title><link href="https://koshiscience.github.io/pages/koshiscience/2022/03/31/website-work.html" rel="alternate" type="text/html" title="一年生のwebサイト作品" /><published>2022-03-31T00:00:00+00:00</published><updated>2022-03-31T00:00:00+00:00</updated><id>https://koshiscience.github.io/pages/koshiscience/2022/03/31/website-work</id><content type="html" xml:base="https://koshiscience.github.io/pages/koshiscience/2022/03/31/website-work.html"><![CDATA[<h1 id="お久しぶりです">お久しぶりです！</h1>
<p>こんにちは</p>

<p>プログラミングチームです</p>

<h1 id="webサイト作品が完成しました">webサイト作品が完成しました！</h1>
<p>この度、中学一年生のwebサイト作品が完成しました！</p>

<p>ぜひ一度、作品を見てみてください</p>

<p>作品は<a href="https://koshiscience.github.io/program-works/website/index.html">こちら</a>！</p>

<p>ソースコードもGitHubで閲覧可能です</p>

<p><a href="https://github.com/koshiscience/program-works/tree/main/website">koshiscience/program-works/website</a></p>

<p><strong>これからも引き続き、研究・製作を頑張っていきますので、応援よろしくおねがいします！</strong></p>]]></content><author><name></name></author><category term="programming" /><summary type="html"><![CDATA[お久しぶりです！ こんにちは]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://koshiscience.github.io/pages/koshiscience/img/2022-03-31-website.png" /><media:content medium="image" url="https://koshiscience.github.io/pages/koshiscience/img/2022-03-31-website.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">紙飛行機実験記 ＃0</title><link href="https://koshiscience.github.io/pages/koshiscience/2021/06/02/kamihikokuki_jikkennki_0.html" rel="alternate" type="text/html" title="紙飛行機実験記 ＃0" /><published>2021-06-02T00:00:00+00:00</published><updated>2021-06-02T00:00:00+00:00</updated><id>https://koshiscience.github.io/pages/koshiscience/2021/06/02/kamihikokuki_jikkennki_0</id><content type="html" xml:base="https://koshiscience.github.io/pages/koshiscience/2021/06/02/kamihikokuki_jikkennki_0.html"><![CDATA[<h1 id="みなさん初めまして">みなさん初めまして！</h1>

<p>私たちは<strong>紙飛行機部門</strong>です！</p>

<p>紙飛行機に関する研究をしています。</p>

<p>今回は、私たちが行ってきた研究を紹介していきます！</p>

<h3 id="研究のきっかけ">研究のきっかけ</h3>

<p>私たちは2020年の2月にこの研究を始めました。</p>

<p><strong>その理由は・・・</strong></p>

<h4 id="世界一とぶ紙飛行機を作りたかったからです"><strong>「世界一とぶ紙飛行機」</strong>を作りたかったからです！！</h4>

<p>皆さんも幼少期のころ紙飛行機を飛ばして遊んでいたことでしょう。</p>

<p>そんな身近な紙飛行機を詳しく研究したいと思い、この研究を始めました。</p>

<h3 id="これからの展望">これからの展望</h3>

<p>世界一とぶ紙飛行機を作成する上で、</p>

<h6 id="安定して飛ばすことが可能な発射台">・安定して飛ばすことが可能な発射台</h6>

<h6 id="よく飛ぶ紙飛行機の折り方">・よく飛ぶ紙飛行機の折り方</h6>

<p>　　　　　　　　　　　</p>

<p>　　　　　　　　　　　　　　について考える必要があります。</p>

<p>また、紙飛行機が非常に<strong>よく飛ぶ角度、紙の大きさ</strong>ついても同様です。</p>

<h4 id="毎月の第４週目に投稿するので楽しみにしてください">毎月の第４週目に投稿するので、楽しみにしてください！</h4>]]></content><author><name></name></author><category term="air-plane" /><summary type="html"><![CDATA[みなさん初めまして！ 私たちは紙飛行機部門です！ 紙飛行機に関する研究をしています。 今回は、私たちが行ってきた研究を紹介していきます！ 研究のきっかけ 私たちは2020年の2月にこの研究を始めました。 その理由は・・・ 「世界一とぶ紙飛行機」を作りたかったからです！！ 皆さんも幼少期のころ紙飛行機を飛ばして遊んでいたことでしょう。 そんな身近な紙飛行機を詳しく研究したいと思い、この研究を始めました。 これからの展望 世界一とぶ紙飛行機を作成する上で、 ・安定して飛ばすことが可能な発射台 ・よく飛ぶ紙飛行機の折り方 　　　　　　　　　　　 　　　　　　　　　　　　　　について考える必要があります。 また、紙飛行機が非常によく飛ぶ角度、紙の大きさついても同様です。 毎月の第４週目に投稿するので、楽しみにしてください！]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://koshiscience.github.io/pages/koshiscience/img/2021-06-02-kamihikouki_omote.png" /><media:content medium="image" url="https://koshiscience.github.io/pages/koshiscience/img/2021-06-02-kamihikouki_omote.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">CNNを導入して筆跡鑑定の認識精度100%を達成！</title><link href="https://koshiscience.github.io/pages/koshiscience/2021/04/05/hisseki_tensorflow.html" rel="alternate" type="text/html" title="CNNを導入して筆跡鑑定の認識精度100%を達成！" /><published>2021-04-05T00:00:00+00:00</published><updated>2021-04-05T00:00:00+00:00</updated><id>https://koshiscience.github.io/pages/koshiscience/2021/04/05/hisseki_tensorflow</id><content type="html" xml:base="https://koshiscience.github.io/pages/koshiscience/2021/04/05/hisseki_tensorflow.html"><![CDATA[<h1 id="お久しぶりです">お久しぶりです</h1>

<p>こんにちは。</p>

<p>筆跡鑑定チームです。</p>

<p>このチームはIchigoJamチームから派生したチームで、<strong>「筆跡鑑定によるユーザー認証」</strong>というテーマで研究を行っています。</p>

<h1 id="筆跡鑑定によるユーザー認証">筆跡鑑定によるユーザー認証</h1>

<p>まず初めに、筆跡鑑定によるユーザー認証について説明します。</p>

<p>この研究は、パスワードや指紋などで行われるユーザー認証を、人工知能による筆跡鑑定に置き換えようというアイデアを基に研究を行っています。</p>

<p>筆跡鑑定に置き換えることによって、</p>

<ul>
  <li>タッチパネルで認証を行えるため、高価なセンサーなどを用いずに、既存のデバイスで認証できる</li>
  <li>手袋などをつけていても認証できる</li>
  <li>偽造しにくい</li>
</ul>

<p>などの利点があります。</p>

<p>この筆跡鑑定を、人工知能の技術で行うためにはどうすればいいかについて、現在研究を進めています。</p>

<h2 id="目標">目標</h2>

<p>実現したときのイメージを説明します。</p>

<ol>
  <li>
    <p>ユーザー登録：自分の名前の筆跡を10枚程度登録してもらう（これを本人かどうかの判断基準に使う）</p>

    <p><img src="/img/2021-04-03-hisseki_image.png" alt="筆跡のイメージ" /></p>
  </li>
  <li>
    <p>認証：筆跡のみを要求→それをもとにどのユーザーか＆本人かを判定する</p>
  </li>
</ol>

<h1 id="ニューラルネットワークとは">ニューラルネットワークとは？</h1>

<p>その前に・・・・・・</p>

<h2 id="機械学習とは">機械学習とは？</h2>

<p>機械学習について説明します。</p>

<p>機械学習とは、<strong>経験からの学習により自動で改善するコンピューターアルゴリズムもしくはその研究領域</strong>（<a href="https://ja.wikipedia.org/wiki/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92">Wikipedia</a>より）のことで、人工知能の一種です。</p>

<p>簡単に言うと、<strong>人間みたいに、見たり聞いたりしたものをもとに成長していく仕組み</strong>です。</p>

<p><strong>訓練データ</strong>と呼ばれるデータを読み込み学習し、それをもとに何かを判定したり動かしたりします。</p>

<p>勉強に例えると、</p>

<ol>
  <li>とりあえず、わからないなりに教科書の問題（<strong>教師データ</strong>）を解いてみる</li>
  <li>間違えたところを訂正する</li>
  <li>1~3を繰り返す</li>
  <li>ある程度力がついてきたらテスト（<strong>テストデータ</strong>）で最終的な実力を測る</li>
  <li>実際に学習内容を様々な場面で活用していく</li>
</ol>

<p>みたいな具合です。</p>

<h2 id="ニューラルネットワークとは-1">ニューラルネットワークとは？</h2>

<p>機械学習のアルゴリズムの一つで、<strong>脳の神経伝達の仕組みを模したもの</strong>です。</p>

<p><a href="https://aizine.ai/glossary-neural-network/">こちらのサイト</a>に詳しい解説があります。</p>

<p>僕たちは、このニューラルネットワークというアルゴリズムを用いて、筆跡鑑定できないかと試行錯誤してきました。</p>

<h1 id="シンプルなニューラルネットワーク">シンプルなニューラルネットワーク</h1>

<p>最初に僕たちが試した、シンプルなニューラルネットワークによる筆跡鑑定について説明します。</p>

<h2 id="環境">環境</h2>

<ul>
  <li>Ruby 2.7（プログラミング言語）</li>
  <li>scikit-learn 0.22（機械学習ライブラリ、機械学習の便利ツールの詰め合わせ）</li>
  <li>PyCall（scikit-learnをRubyから呼びだすためのライブラリ）</li>
</ul>

<p>scikit-learnは本来、Pythonというプログラミング言語のためのライブラリで、Rubyで使うことはできません。</p>

<p>ですが、<strong>最終的にwebアプリにすることを考え</strong>、サーバーに強いRubyからPyCallを用いてscikit-learnを使うことにしました。</p>

<h2 id="pycallを用いた実装">PyCallを用いた実装</h2>

<p>PyCallを用いると、PythonのライブラリをRubyから呼び出して使うことができます。</p>

<p>PyCallの読み込み（Ruby）</p>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">require</span> <span class="s2">"pycall/import"</span>
<span class="kp">include</span> <span class="no">PyCall</span><span class="o">::</span><span class="no">Import</span>
</code></pre></div></div>

<p>※事前にRubyとPython、またPyCallと使いたいPythonのライブラリがインストールされている環境でないと動きません。</p>

<p>PyCallを読み込めば、<code class="language-plaintext highlighter-rouge">pyimport</code>や<code class="language-plaintext highlighter-rouge">pyfrom</code>などのメソッドが使えるようになり、Pythonのライブラリを読み込んで動かすことができるようになります。</p>

<p>Pythonのライブラリのチュートリアルやドキュメントのコードは、Pythonで書かれているため<strong>うまくRubyに書き換える</strong>必要があります。</p>

<p>ライブラリの読み込み（Python）</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># scikit-learnの例
</span><span class="kn">import</span> <span class="nn">sklearn.neural_network</span> <span class="kn">import</span> <span class="nn">MLPClassifier</span>

<span class="c1"># TensorFlowの例
</span><span class="kn">from</span> <span class="nn">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">layers</span><span class="p">,</span> <span class="n">models</span>

<span class="c1"># そのほかのライブラリの例
</span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
</code></pre></div></div>

<p>（Ruby）</p>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># scikit-learnの例</span>
<span class="n">pyimport</span> <span class="s2">"sklearn.neural_network"</span><span class="p">,</span> <span class="ss">import: </span><span class="s2">"MLPClassifier"</span>

<span class="c1"># Tensorflowの例</span>
<span class="n">pyfrom</span> <span class="s2">"tensorflow"</span><span class="p">,</span> <span class="ss">import: </span><span class="s2">"keras"</span>
<span class="n">pyfrom</span> <span class="s2">"tensorflow.keras"</span><span class="p">,</span> <span class="ss">import: </span><span class="p">[</span><span class="s2">"datasets"</span><span class="p">,</span> <span class="s2">"layers"</span><span class="p">,</span> <span class="s2">"models"</span><span class="p">]</span> <span class="c1"># 複数指定するときは配列を使う</span>

<span class="c1"># そのほかのライブラリの例</span>
<span class="n">pyimport</span> <span class="s2">"numpy"</span><span class="p">,</span> <span class="ss">as: </span><span class="s2">"numpy"</span>

<span class="c1"># "文字列" の代わりに :シンボル を用いることもできる</span>
<span class="n">pyfrom</span> <span class="ss">:tensorflow</span><span class="p">,</span> <span class="ss">import: :keras</span>
<span class="c1"># コンマが入る場合は "文字列" を使う、配列でも :シンボル を使える</span>
<span class="n">pyfrom</span> <span class="s2">"tensorflow.keras"</span><span class="p">,</span> <span class="ss">import: </span><span class="p">[</span><span class="ss">:datasets</span><span class="p">,</span> <span class="ss">:layers</span><span class="p">,</span> <span class="ss">:models</span><span class="p">]</span>
</code></pre></div></div>

<p>インスタンスを作る（Python）</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># scikit-learnのニューラルネットワークの例
</span><span class="n">estimator</span> <span class="o">=</span> <span class="n">MLPClassifier</span><span class="p">(</span>
	<span class="n">solver</span><span class="o">=</span><span class="s">"lbfgs"</span><span class="p">,</span>
    <span class="n">activation</span><span class="o">=</span><span class="s">"logistic"</span><span class="p">,</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span>
    <span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span>
<span class="p">)</span>
</code></pre></div></div>

<p>（Ruby）</p>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># scikit-learnのニューラルネットワークの例</span>
<span class="n">estimator</span> <span class="o">=</span> <span class="no">MLPClassifier</span><span class="p">.</span><span class="nf">new</span><span class="p">(</span> <span class="c1"># .newをつける</span>
	<span class="ss">solver: </span><span class="s2">"lbfgs"</span><span class="p">,</span> <span class="c1"># =ではなく:を用いる</span>
    <span class="ss">activation: :logistic</span><span class="p">,</span> <span class="c1"># :シンボル も使える</span>
    <span class="ss">alpha: </span><span class="mf">1e-5</span><span class="p">,</span> <span class="c1"># 指数表現はそのままでも問題なし</span>
    <span class="ss">hidden_layer_sizes: </span><span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="c1"># タプル（配列のようなもの）は配列で表現</span>
    <span class="ss">random_state: </span><span class="mi">1</span>
<span class="p">)</span>
</code></pre></div></div>

<p>関数を呼び出す（Python)</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># scikit-learnの学習させる関数
</span><span class="n">estimator</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</code></pre></div></div>

<p>（Ruby）</p>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># scikit-learnの学習させる関数</span>
<span class="n">estimator</span><span class="p">.</span><span class="nf">fit</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="c1"># 括弧はなくてもよい</span>
</code></pre></div></div>

<h2 id="テストの条件">テストの条件</h2>

<ol>
  <li>
    <p>筆跡データ</p>

    <p>1人につき、教師データ：30枚、テストデータ：10枚の合計40枚の√記号を用いります。</p>

    <p>これを2人分集めました。</p>

    <p><img src="/img/2021-04-03-base0.png" alt="筆跡の例" /><img src="/img/2021-04-03-base1.png" alt="筆跡の例" /></p>

    <p>↑こんな感じ</p>

    <p>人によって癖がかなりある√記号は、<strong>機械にとって認識しやすい</strong>ためこの記号を用いりました。</p>

    <p>今回はあくまでもテストなので、<strong>傾向などをつかむために良い結果が出やすいよう</strong>に機械に有利な条件で進めていきました。</p>
  </li>
  <li>
    <p>検証方法</p>

    <p>別の2人が書いた筆跡を、どちらが書いたものか分類する精度を測ります。</p>

    <p>まず、教師データを分類器に学習させます。</p>

    <p>教師データはどちらが書いたかのラベルが貼ってあり、分類器はどちらが書いたかを認識できます。</p>

    <p>学習出来たら、テストデータで分類させて、どのくらい分類できるのかを検証します。</p>
  </li>
</ol>

<h2 id="検証結果">検証結果</h2>

<p>いろいろなハイパーパラメータ（最初に設定しなければいけないパラメータ）を試したところ、<strong>最大で平均約80%の予測精度</strong>を達成しました。</p>

<p>ネットワークの設定</p>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">estimator</span> <span class="o">=</span> <span class="no">MLPClassifier</span><span class="p">.</span><span class="nf">new</span><span class="p">(</span>
  <span class="ss">hidden_layer_sizes: </span><span class="p">[</span><span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">],</span>
  <span class="ss">activation: </span><span class="s2">"tanh"</span><span class="p">,</span>
  <span class="ss">solver: </span><span class="s2">"lbfgs"</span><span class="p">,</span>
  <span class="ss">max_iter: </span><span class="mi">100000</span><span class="p">,</span>
  <span class="ss">tol: </span><span class="mf">0.0001</span>
<span class="p">)</span>
</code></pre></div></div>

<p>scikit-learnのパラメータですが、表記方法はRubyになっています。</p>

<h1 id="畳み込みニューラルネットワークcnn">畳み込みニューラルネットワーク（CNN）</h1>

<p>ですが、80%の予測精度では<strong>とても個人情報や金銭がかかっているユーザー認証で実用できる精度</strong>ではないので、画像認識に有利と言われている<strong>畳み込みニューラルネットワーク</strong>を導入しました。</p>

<p>畳み込みニューラルネットワークは、<strong>ニューラルネットワークに人間の物体認識の仕組みのモデルを追加したもの</strong>で、現在のAIブームの引き金となったものです。</p>

<p>これについても<a href="https://www.imagazine.co.jp/%E7%95%B3%E3%81%BF%E8%BE%BC%E3%81%BF%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF%E3%81%AE%E3%80%8C%E5%9F%BA%E7%A4%8E%E3%81%AE%E5%9F%BA%E7%A4%8E%E3%80%8D%E3%82%92%E7%90%86%E8%A7%A3%E3%81%99/">こちらのサイト</a>に詳しい解説があります。</p>

<h2 id="環境-1">環境</h2>

<ul>
  <li>Ruby 2.7（プログラミング言語）</li>
  <li>TensorFlow 2.4（機械学習ライブラリ）</li>
  <li>PyCall（scikit-learnをRubyから呼びだすためのライブラリ）</li>
</ul>

<p>プログラミング言語は変わらないのですが、ライブラリを<strong>scikit-learnからTensorFlowに変更</strong>しました。</p>

<p>TensorFlowの方が、よりニューラルネットワーク向きで、ネットワークの層ごとに細かくいろいろなハイパーパラメータを設定出来るなどの利点があります。</p>

<p>その中でも、<strong>畳み込みニューラルネットワークを簡単に使うことができる</strong>のは大きな利点です。</p>

<h2 id="検証結果-1">検証結果</h2>

<p>まず試しに、<a href="https://www.tensorflow.org/tutorials/images/cnn?hl=ja">このチュートリアル</a>をもとにCNNのネットワークを設定し、集めた筆跡データで認識するようにしたところ、<strong>いきなり100%の精度</strong>を出すことができました。</p>

<p>ネットワークの設定</p>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="no">Sequential</span><span class="p">.</span><span class="nf">new</span><span class="p">([</span>
    <span class="n">layers</span><span class="o">.</span><span class="no">Conv2D</span><span class="p">.</span><span class="nf">new</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="ss">activation: :relu</span><span class="p">,</span> <span class="ss">input_shape: </span><span class="p">[</span><span class="mi">128</span><span class="p">,</span> <span class="mi">118</span><span class="p">,</span> <span class="mi">1</span><span class="p">]),</span>
    <span class="n">layers</span><span class="o">.</span><span class="no">MaxPooling2D</span><span class="p">.</span><span class="nf">new</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">]),</span>
    <span class="n">layers</span><span class="o">.</span><span class="no">Conv2D</span><span class="p">.</span><span class="nf">new</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="ss">activation: :relu</span><span class="p">),</span>
    <span class="n">layers</span><span class="o">.</span><span class="no">MaxPooling2D</span><span class="p">.</span><span class="nf">new</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">]),</span>
    <span class="n">layers</span><span class="o">.</span><span class="no">Conv2D</span><span class="p">.</span><span class="nf">new</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="ss">activation: :relu</span><span class="p">),</span>
    <span class="n">layers</span><span class="o">.</span><span class="no">Flatten</span><span class="p">.</span><span class="nf">new</span><span class="p">,</span>
    <span class="n">layers</span><span class="o">.</span><span class="no">Dense</span><span class="p">.</span><span class="nf">new</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="ss">activation: :relu</span><span class="p">),</span>
    <span class="n">layers</span><span class="o">.</span><span class="no">Dense</span><span class="p">.</span><span class="nf">new</span><span class="p">(</span><span class="n">members</span><span class="p">.</span><span class="nf">length</span><span class="p">,</span> <span class="ss">activation: :softmax</span><span class="p">)</span>
<span class="p">])</span>
</code></pre></div></div>

<p>もちろん、条件は先ほどのscikit-learnの時と変わりません。</p>

<p>教師データとテストデータを入れ替えたりして何度かやってみても、100%の結果が変わることはありませんでした。</p>

<p>さらには、2人の分類からもう1人分の筆跡を増やして、<strong>3人の分類に変更しても100%の結果が変わることはありませんでした。</strong></p>

<p>このことから、<strong>CNNは画像認識においてかなり強力</strong>であることを実感しました。</p>

<h1 id="今後の課題">今後の課題</h1>

<p>今回、<strong>CNNを使うとかなり高い精度を実現</strong>することが可能だとわかりました。</p>

<p>ですが、まだまだハイパーパラメータはとりあえずでチュートリアルのものを使っているだけで、少ししか調整していません。</p>

<p>また、分類する人数は3人と、実用には及ばないレベルなのでもっと増やしても精度を保てることを確認しなければなりません。</p>

<p>人数を増やすと、認識精度以外にも処理速度などもかなり低下する恐れがあります。</p>

<p>計算速度と精度のバランスを、ハイパーパラメータで調整する必要が出てくるでしょう。</p>

<p>目標は<strong>10人の筆跡を100%に近い精度で分類できるようにする</strong>ことです。</p>

<p>実際にユーザー認証システムを実装する場合は、名前でまず分類して、その中で誰の筆跡か分類することになるでしょう。</p>

<p>同姓同名の人は、平均約4人（<a href="https://www.insightnow.jp/article/5069?page=2#:~:text=%E3%80%8C%E5%90%8C%E5%A7%93%E5%90%8C%E5%90%8D%E8%BE%9E%E5%85%B8%E3%80%8D%E3%81%AB%E3%81%AF,%E7%A8%8B%E5%BA%A6%E3%81%AA%E3%82%8F%E3%81%91%E3%81%A7%E3%81%82%E3%82%8B%E3%80%82">このサイト</a>より）とかなり少ないため、同じ文字列が記入されている筆跡を分類する場合は10人ほどを正確に分類できれば十分だろう考えたため、10人を目標にしました。</p>

<p>これを目標に、研究を頑張っていきます！</p>

<p>今後も、僕たちの応援よろしくお願いします！</p>]]></content><author><name></name></author><category term="Ruby" /><category term="hisseki" /><category term="programming" /><summary type="html"><![CDATA[お久しぶりです こんにちは。 筆跡鑑定チームです。 このチームはIchigoJamチームから派生したチームで、「筆跡鑑定によるユーザー認証」というテーマで研究を行っています。 筆跡鑑定によるユーザー認証 まず初めに、筆跡鑑定によるユーザー認証について説明します。 この研究は、パスワードや指紋などで行われるユーザー認証を、人工知能による筆跡鑑定に置き換えようというアイデアを基に研究を行っています。 筆跡鑑定に置き換えることによって、 タッチパネルで認証を行えるため、高価なセンサーなどを用いずに、既存のデバイスで認証できる 手袋などをつけていても認証できる 偽造しにくい などの利点があります。 この筆跡鑑定を、人工知能の技術で行うためにはどうすればいいかについて、現在研究を進めています。 目標 実現したときのイメージを説明します。 ユーザー登録：自分の名前の筆跡を10枚程度登録してもらう（これを本人かどうかの判断基準に使う） 認証：筆跡のみを要求→それをもとにどのユーザーか＆本人かを判定する ニューラルネットワークとは？ その前に・・・・・・ 機械学習とは？ 機械学習について説明します。 機械学習とは、経験からの学習により自動で改善するコンピューターアルゴリズムもしくはその研究領域（Wikipediaより）のことで、人工知能の一種です。 簡単に言うと、人間みたいに、見たり聞いたりしたものをもとに成長していく仕組みです。 訓練データと呼ばれるデータを読み込み学習し、それをもとに何かを判定したり動かしたりします。 勉強に例えると、 とりあえず、わからないなりに教科書の問題（教師データ）を解いてみる 間違えたところを訂正する 1~3を繰り返す ある程度力がついてきたらテスト（テストデータ）で最終的な実力を測る 実際に学習内容を様々な場面で活用していく みたいな具合です。 ニューラルネットワークとは？ 機械学習のアルゴリズムの一つで、脳の神経伝達の仕組みを模したものです。 こちらのサイトに詳しい解説があります。 僕たちは、このニューラルネットワークというアルゴリズムを用いて、筆跡鑑定できないかと試行錯誤してきました。 シンプルなニューラルネットワーク 最初に僕たちが試した、シンプルなニューラルネットワークによる筆跡鑑定について説明します。 環境 Ruby 2.7（プログラミング言語） scikit-learn 0.22（機械学習ライブラリ、機械学習の便利ツールの詰め合わせ） PyCall（scikit-learnをRubyから呼びだすためのライブラリ） scikit-learnは本来、Pythonというプログラミング言語のためのライブラリで、Rubyで使うことはできません。 ですが、最終的にwebアプリにすることを考え、サーバーに強いRubyからPyCallを用いてscikit-learnを使うことにしました。 PyCallを用いた実装 PyCallを用いると、PythonのライブラリをRubyから呼び出して使うことができます。 PyCallの読み込み（Ruby） require "pycall/import" include PyCall::Import ※事前にRubyとPython、またPyCallと使いたいPythonのライブラリがインストールされている環境でないと動きません。 PyCallを読み込めば、pyimportやpyfromなどのメソッドが使えるようになり、Pythonのライブラリを読み込んで動かすことができるようになります。 Pythonのライブラリのチュートリアルやドキュメントのコードは、Pythonで書かれているためうまくRubyに書き換える必要があります。 ライブラリの読み込み（Python） # scikit-learnの例 import sklearn.neural_network import MLPClassifier # TensorFlowの例 from tensorflow import keras from tensorflow.keras import datasets, layers, models # そのほかのライブラリの例 import numpy as np （Ruby） # scikit-learnの例 pyimport "sklearn.neural_network", import: "MLPClassifier" # Tensorflowの例 pyfrom "tensorflow", import: "keras" pyfrom "tensorflow.keras", import: ["datasets", "layers", "models"] # 複数指定するときは配列を使う # そのほかのライブラリの例 pyimport "numpy", as: "numpy" # "文字列" の代わりに :シンボル を用いることもできる pyfrom :tensorflow, import: :keras # コンマが入る場合は "文字列" を使う、配列でも :シンボル を使える pyfrom "tensorflow.keras", import: [:datasets, :layers, :models] インスタンスを作る（Python） # scikit-learnのニューラルネットワークの例 estimator = MLPClassifier( solver="lbfgs", activation="logistic", alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1 ) （Ruby） # scikit-learnのニューラルネットワークの例 estimator = MLPClassifier.new( # .newをつける solver: "lbfgs", # =ではなく:を用いる activation: :logistic, # :シンボル も使える alpha: 1e-5, # 指数表現はそのままでも問題なし hidden_layer_sizes: [5, 2], # タプル（配列のようなもの）は配列で表現 random_state: 1 ) 関数を呼び出す（Python) # scikit-learnの学習させる関数 estimator.fit(images, labels) （Ruby） # scikit-learnの学習させる関数 estimator.fit images, labels # 括弧はなくてもよい テストの条件 筆跡データ 1人につき、教師データ：30枚、テストデータ：10枚の合計40枚の√記号を用いります。 これを2人分集めました。 ↑こんな感じ 人によって癖がかなりある√記号は、機械にとって認識しやすいためこの記号を用いりました。 今回はあくまでもテストなので、傾向などをつかむために良い結果が出やすいように機械に有利な条件で進めていきました。 検証方法 別の2人が書いた筆跡を、どちらが書いたものか分類する精度を測ります。 まず、教師データを分類器に学習させます。 教師データはどちらが書いたかのラベルが貼ってあり、分類器はどちらが書いたかを認識できます。 学習出来たら、テストデータで分類させて、どのくらい分類できるのかを検証します。 検証結果 いろいろなハイパーパラメータ（最初に設定しなければいけないパラメータ）を試したところ、最大で平均約80%の予測精度を達成しました。 ネットワークの設定 estimator = MLPClassifier.new( hidden_layer_sizes: [64, 128], activation: "tanh", solver: "lbfgs", max_iter: 100000, tol: 0.0001 ) scikit-learnのパラメータですが、表記方法はRubyになっています。 畳み込みニューラルネットワーク（CNN） ですが、80%の予測精度ではとても個人情報や金銭がかかっているユーザー認証で実用できる精度ではないので、画像認識に有利と言われている畳み込みニューラルネットワークを導入しました。 畳み込みニューラルネットワークは、ニューラルネットワークに人間の物体認識の仕組みのモデルを追加したもので、現在のAIブームの引き金となったものです。 これについてもこちらのサイトに詳しい解説があります。 環境 Ruby 2.7（プログラミング言語） TensorFlow 2.4（機械学習ライブラリ） PyCall（scikit-learnをRubyから呼びだすためのライブラリ） プログラミング言語は変わらないのですが、ライブラリをscikit-learnからTensorFlowに変更しました。 TensorFlowの方が、よりニューラルネットワーク向きで、ネットワークの層ごとに細かくいろいろなハイパーパラメータを設定出来るなどの利点があります。 その中でも、畳み込みニューラルネットワークを簡単に使うことができるのは大きな利点です。 検証結果 まず試しに、このチュートリアルをもとにCNNのネットワークを設定し、集めた筆跡データで認識するようにしたところ、いきなり100%の精度を出すことができました。 ネットワークの設定 model = models.Sequential.new([ layers.Conv2D.new(64, [5, 5], activation: :relu, input_shape: [128, 118, 1]), layers.MaxPooling2D.new([4, 4]), layers.Conv2D.new(64, [5, 5], activation: :relu), layers.MaxPooling2D.new([4, 4]), layers.Conv2D.new(32, [5, 5], activation: :relu), layers.Flatten.new, layers.Dense.new(128, activation: :relu), layers.Dense.new(members.length, activation: :softmax) ]) もちろん、条件は先ほどのscikit-learnの時と変わりません。 教師データとテストデータを入れ替えたりして何度かやってみても、100%の結果が変わることはありませんでした。 さらには、2人の分類からもう1人分の筆跡を増やして、3人の分類に変更しても100%の結果が変わることはありませんでした。 このことから、CNNは画像認識においてかなり強力であることを実感しました。 今後の課題 今回、CNNを使うとかなり高い精度を実現することが可能だとわかりました。 ですが、まだまだハイパーパラメータはとりあえずでチュートリアルのものを使っているだけで、少ししか調整していません。 また、分類する人数は3人と、実用には及ばないレベルなのでもっと増やしても精度を保てることを確認しなければなりません。 人数を増やすと、認識精度以外にも処理速度などもかなり低下する恐れがあります。 計算速度と精度のバランスを、ハイパーパラメータで調整する必要が出てくるでしょう。 目標は10人の筆跡を100%に近い精度で分類できるようにすることです。 実際にユーザー認証システムを実装する場合は、名前でまず分類して、その中で誰の筆跡か分類することになるでしょう。 同姓同名の人は、平均約4人（このサイトより）とかなり少ないため、同じ文字列が記入されている筆跡を分類する場合は10人ほどを正確に分類できれば十分だろう考えたため、10人を目標にしました。 これを目標に、研究を頑張っていきます！ 今後も、僕たちの応援よろしくお願いします！]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://koshiscience.github.io/pages/koshiscience/img/2020-04-03-header.png" /><media:content medium="image" url="https://koshiscience.github.io/pages/koshiscience/img/2020-04-03-header.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">お手軽webサーバー、Sinatraはじめのいっぽ！</title><link href="https://koshiscience.github.io/pages/koshiscience/2020/09/28/sinatra_first.html" rel="alternate" type="text/html" title="お手軽webサーバー、Sinatraはじめのいっぽ！" /><published>2020-09-28T00:00:00+00:00</published><updated>2020-09-28T00:00:00+00:00</updated><id>https://koshiscience.github.io/pages/koshiscience/2020/09/28/sinatra_first</id><content type="html" xml:base="https://koshiscience.github.io/pages/koshiscience/2020/09/28/sinatra_first.html"><![CDATA[<h1 id="webサーバーを作ろう">webサーバーを作ろう！</h1>

<p>こんにちは。高志中学校サイエンス部プログラミング班です。</p>

<p>今回のブログでは、Sinatraというフレームワークを使って、簡単なwebサーバーを作ってみようと思います！</p>

<h1 id="sinatraってなに">Sinatraってなに？</h1>

<p>Sinatraは、Rubyというプログラミング言語で動くwebサーバーフレームワークです。</p>

<p>分かりにくく感じますが、、、簡単に言うと、サーバーを楽に作れるものとなります。</p>

<p>Rubyのwebサーバーフレームワークというと、Ruby on Railsが有名ですが、Sinatraのほうがシンプルで単純なのでわかりやすいです。</p>

<h1 id="早速インストール">早速インストール！</h1>

<p>早速インストール！のその前に・・・</p>

<p>RubyがPCにインストールされている必要があります。</p>

<p>インストールの方法はOSによって異なるので、「ruby インストール windows」のように検索して調べてみてください。</p>

<p>Rubyのインストールができたら、早速Sinatraのインストールをしていきましょう。</p>

<p>WindowsならWindows PowerShell、Macならターミナルを起動しましょう。</p>

<p>起動出来たら、下のように打ってみましょう。</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>gem install sinatra
</code></pre></div></div>

<p>これを入力すると、Sinatra本体のインストールが始まります。</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>gem install sinatra-contrib
</code></pre></div></div>

<p>で、Sinatra関連の便利ツールもインストールされます。</p>

<h1 id="webサーバーでhello-world">webサーバーで”Hello World”</h1>

<p>それでは、定番の”Hello World”を表示するプログラムを書いてみましょう。</p>

<p>どこかに作業用のフォルダーを作ってみましょう。</p>

<p>それから、AtomやVisual Studio Codeなどのテキストエディタでそのフォルダーを開きます。</p>

<p>そして、example.rbというファイルを作り、</p>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">require</span> <span class="s2">"sinatra"</span>
<span class="nb">require</span> <span class="s2">"sinatra/reloader"</span>

<span class="n">get</span> <span class="s2">"/"</span> <span class="k">do</span>
    <span class="s2">"Hello World"</span>
<span class="k">end</span>
</code></pre></div></div>

<p>と入力しましょう。</p>

<p>次に、example.rbを実行します。</p>

<p>ターミナルなどで、</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cd /home/pi/ruby
</code></pre></div></div>

<p>と入力して、フォルダーの中へ移動します（/home/pi/rubyの部分はフォルダーのパスを入力してください）</p>

<p>そこで、</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ruby example.rb
</code></pre></div></div>

<p>として、example.rbを実行してみましょう。</p>

<p>いろいろログが出てきますが、”Hello World”とは表示されませんね。</p>

<p>また、何も起こらずにコマンドを打つ画面に戻ってしまったら、エラーが発生しているかもしれません。</p>

<p>プログラムの中身や手順をよく確認してみてください。</p>

<p>うまくいってたら、すでにサーバーが起動しています！</p>

<p>ブラウザで、<a href="https://localhost:4567">https://localhost:4567/</a>にアクセスしてみると・・・</p>

<p>どうでしょうか？</p>

<p>Hello Worldと表示されたら成功です！</p>

<h1 id="プログラムの構造">プログラムの構造</h1>

<p>もう一度、さっきのプログラムを見てみましょう</p>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">require</span> <span class="s2">"sinatra"</span>
<span class="nb">require</span> <span class="s2">"sinatra/reloader"</span>

<span class="n">get</span> <span class="s2">"/"</span> <span class="k">do</span>
    <span class="s2">"Hello World"</span>
<span class="k">end</span>
</code></pre></div></div>

<p>1行目：Sinatraを読み込む</p>

<p>2行目：実行中にファイルが変更された場合、その変更を反映するツールを読み込む</p>

<p>4行目：”/”の要求を受けたら、</p>

<p>5行目：”Hello World”を返して</p>

<p>6行目：get “/”の処理を終わる</p>

<p>こんな感じです。</p>

<p>6行目”Hello World”の部分を変更すると、どうなるでしょうか？</p>

<p>7行目”/”の部分を変更すると、どうなるでしょうか？</p>

<p>いろいろ試してみましょう！</p>

<h1 id="改造のポイント">改造のポイント</h1>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">get</span> <span class="s2">"/"</span> <span class="k">do</span>
    <span class="s2">"Hello World"</span>
<span class="k">end</span>
</code></pre></div></div>

<p>の部分では、do~endの間に”Hello World”という文字列しかないですが、ここには処理を書き込むこともできます。</p>

<p>Rubyの処理を書き込めるので、いろいろ調べて試してみてください！</p>

<p>試しにカウント機能作ってみました。</p>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">require</span> <span class="s2">"sinatra"</span>
<span class="nb">require</span> <span class="s2">"sinatra/reloader"</span>

<span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>

<span class="n">get</span> <span class="s2">"/"</span> <span class="k">do</span>
    <span class="n">i</span> <span class="o">=</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="s2">"</span><span class="si">#{</span><span class="n">i</span><span class="si">}</span><span class="s2">"</span>
<span class="k">end</span>
</code></pre></div></div>

<p>一回読み込むごとに、表示される数字が増えていきます！</p>

<p>このように、いろいろ改造してみましょう！</p>

<h2 id="報告">報告</h2>

<p>現在、ブログのタグ機能がうまく機能していません。</p>

<p>工夫して実装したのですが、GitHub Pagesではうまく動かないようです。</p>

<p>そのため、代わりの方法を考えています。</p>

<p>タグ機能の復活までしばらくお待ちください。</p>]]></content><author><name></name></author><category term="Ruby" /><category term="programming" /><summary type="html"><![CDATA[webサーバーを作ろう！ こんにちは。高志中学校サイエンス部プログラミング班です。 今回のブログでは、Sinatraというフレームワークを使って、簡単なwebサーバーを作ってみようと思います！ Sinatraってなに？ Sinatraは、Rubyというプログラミング言語で動くwebサーバーフレームワークです。 分かりにくく感じますが、、、簡単に言うと、サーバーを楽に作れるものとなります。 Rubyのwebサーバーフレームワークというと、Ruby on Railsが有名ですが、Sinatraのほうがシンプルで単純なのでわかりやすいです。 早速インストール！ 早速インストール！のその前に・・・ RubyがPCにインストールされている必要があります。 インストールの方法はOSによって異なるので、「ruby インストール windows」のように検索して調べてみてください。 Rubyのインストールができたら、早速Sinatraのインストールをしていきましょう。 WindowsならWindows PowerShell、Macならターミナルを起動しましょう。 起動出来たら、下のように打ってみましょう。 gem install sinatra これを入力すると、Sinatra本体のインストールが始まります。 gem install sinatra-contrib で、Sinatra関連の便利ツールもインストールされます。 webサーバーで”Hello World” それでは、定番の”Hello World”を表示するプログラムを書いてみましょう。 どこかに作業用のフォルダーを作ってみましょう。 それから、AtomやVisual Studio Codeなどのテキストエディタでそのフォルダーを開きます。 そして、example.rbというファイルを作り、 require "sinatra" require "sinatra/reloader" get "/" do "Hello World" end と入力しましょう。 次に、example.rbを実行します。 ターミナルなどで、 cd /home/pi/ruby と入力して、フォルダーの中へ移動します（/home/pi/rubyの部分はフォルダーのパスを入力してください） そこで、 ruby example.rb として、example.rbを実行してみましょう。 いろいろログが出てきますが、”Hello World”とは表示されませんね。 また、何も起こらずにコマンドを打つ画面に戻ってしまったら、エラーが発生しているかもしれません。 プログラムの中身や手順をよく確認してみてください。 うまくいってたら、すでにサーバーが起動しています！ ブラウザで、https://localhost:4567/にアクセスしてみると・・・ どうでしょうか？ Hello Worldと表示されたら成功です！ プログラムの構造 もう一度、さっきのプログラムを見てみましょう require "sinatra" require "sinatra/reloader" get "/" do "Hello World" end 1行目：Sinatraを読み込む 2行目：実行中にファイルが変更された場合、その変更を反映するツールを読み込む 4行目：”/”の要求を受けたら、 5行目：”Hello World”を返して 6行目：get “/”の処理を終わる こんな感じです。 6行目”Hello World”の部分を変更すると、どうなるでしょうか？ 7行目”/”の部分を変更すると、どうなるでしょうか？ いろいろ試してみましょう！ 改造のポイント get "/" do "Hello World" end の部分では、do~endの間に”Hello World”という文字列しかないですが、ここには処理を書き込むこともできます。 Rubyの処理を書き込めるので、いろいろ調べて試してみてください！ 試しにカウント機能作ってみました。 require "sinatra" require "sinatra/reloader" i = 0 get "/" do i = i + 1 "#{i}" end 一回読み込むごとに、表示される数字が増えていきます！ このように、いろいろ改造してみましょう！ 報告 現在、ブログのタグ機能がうまく機能していません。 工夫して実装したのですが、GitHub Pagesではうまく動かないようです。 そのため、代わりの方法を考えています。 タグ機能の復活までしばらくお待ちください。]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://koshiscience.github.io/pages/koshiscience/img/2020-01-27-koshischool.jpg" /><media:content medium="image" url="https://koshiscience.github.io/pages/koshiscience/img/2020-01-27-koshischool.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">IchigoJamを使ってキラキラアクセサリーを作ろう！</title><link href="https://koshiscience.github.io/pages/koshiscience/2020/03/26/kirakira.html" rel="alternate" type="text/html" title="IchigoJamを使ってキラキラアクセサリーを作ろう！" /><published>2020-03-26T00:00:00+00:00</published><updated>2020-03-26T00:00:00+00:00</updated><id>https://koshiscience.github.io/pages/koshiscience/2020/03/26/kirakira</id><content type="html" xml:base="https://koshiscience.github.io/pages/koshiscience/2020/03/26/kirakira.html"><![CDATA[<h1 id="はじめに">はじめに</h1>
<p>こんにちは。</p>

<p>IchigoJamチームです。</p>

<p>突然ですが、最近IchigoJamのOSが新しくなったことをご存じですか？</p>

<p>12月に、<a href="https://fukuno.jig.jp">福野さん</a>がIchigoJam 1.4を正式リリースしました。</p>

<p>このアップデートでたくさんの機能がIchigoJamに追加されたのですが、今回はその中の<code class="language-plaintext highlighter-rouge">WS.LED</code>コマンドを使って、お手軽キラキラアクセサリーを作りましょう！</p>

<h1 id="準備するもの">準備するもの</h1>
<ul>
  <li>Ichigojam(BASIC 1.4が書き込み済み。書き込み方法については<a href="https://15jamrecipe.jimdofree.com/%E5%91%A8%E8%BE%BA%E6%A9%9F%E5%99%A8/%E3%83%91%E3%82%BD%E3%82%B3%E3%83%B3%E3%81%A8%E6%8E%A5%E7%B6%9A/%E3%83%95%E3%82%A1%E3%83%BC%E3%83%A0%E3%82%A6%E3%82%A7%E3%82%A2%E6%9B%B4%E6%96%B0/">こちら</a>)</li>
  <li>WS2812B内蔵LEDテープ(amazonなどで「WS2812B LEDテープ」などと検索してみてください)</li>
  <li>IchigoJamでプログラミングする環境</li>
  <li>モバイルバッテリーもしくは電池ボックスと乾電池(3本)</li>
  <li>はんだごてや導線(LEDテープを必要な長さに調節するのに使います)</li>
  <li>あれば、装飾したいマフラー、帽子など</li>
</ul>

<h1 id="ledテープの準備">LEDテープの準備</h1>
<p>まず、どこをどのように装飾するのかを考えます。</p>

<p>LEDテープは33個までに収めてください。</p>

<p>次に、必要な長さにカットします。</p>

<p>そして各端子に導線をはんだ付けして準備完了です。</p>

<h1 id="プログラミング">プログラミング</h1>
<p>IchigoJamにプログラミングしていきます。</p>

<p>まず、SAVE0にあるプログラムを退避させてください。</p>

<p><code class="language-plaintext highlighter-rouge">WS.LED {数1}</code>コマンドは、配列を最初から参照し、３つずつ読み取ってその３つの値をred、green、blueと認識して、光らせていきます。</p>

<p>一番単純な、全部のLEDをランダムに光らせるプログラムはこれです</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1 @ARUN
10 FORI=0TO29:[I]=RND(100):NEXT:WS.LED10:WAIT10:CONT
</code></pre></div></div>
<p><code class="language-plaintext highlighter-rouge">SAVE0</code>して保存してください。</p>

<p>他にも、自分でいろいろ試してみてください。</p>

<h1 id="接続">接続</h1>
<p>IchigoJam側の端子と、LEDテープ側の端子を接続していきます。</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">IchigoJam側</th>
      <th style="text-align: center">LEDテープ側</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">GND</td>
      <td style="text-align: center">GND</td>
    </tr>
    <tr>
      <td style="text-align: center">5V</td>
      <td style="text-align: center">VCC</td>
    </tr>
    <tr>
      <td style="text-align: center">LED</td>
      <td style="text-align: center">DO</td>
    </tr>
  </tbody>
</table>

<p>上を参考に配線してみてください。</p>

<p>この状態で、IchigoJamの電源を入れると動き出します。</p>

<p>プログラムの最初に「@ARUN」という記述をしてSAVE0に保存すると、起動時に自動実行されるからです。(IchigoJam 1.4の新機能)</p>

<p>持ち運べるようにするには、モバイルバッテリーをつなげるか、乾電池の＋をIchigoJamの5Vに、ーをIchigoJamのGNDにさしてください。</p>

<h1 id="完成">完成</h1>
<p>僕たちは、ネックウォーマーや帽子にLEDをつけて遊びました！</p>

<p>プログラムの設定で、かなり明るくなるようにしてあるので、結構まぶしいです。</p>

<p>そのあたりは、自分で試して変更してください。</p>

<p>このキラキラアクセサリーで、パーティーなどを盛り上げよう！</p>]]></content><author><name></name></author><category term="IchigoJam" /><category term="programming" /><summary type="html"><![CDATA[はじめに こんにちは。 IchigoJamチームです。 突然ですが、最近IchigoJamのOSが新しくなったことをご存じですか？ 12月に、福野さんがIchigoJam 1.4を正式リリースしました。 このアップデートでたくさんの機能がIchigoJamに追加されたのですが、今回はその中のWS.LEDコマンドを使って、お手軽キラキラアクセサリーを作りましょう！ 準備するもの Ichigojam(BASIC 1.4が書き込み済み。書き込み方法についてはこちら) WS2812B内蔵LEDテープ(amazonなどで「WS2812B LEDテープ」などと検索してみてください) IchigoJamでプログラミングする環境 モバイルバッテリーもしくは電池ボックスと乾電池(3本) はんだごてや導線(LEDテープを必要な長さに調節するのに使います) あれば、装飾したいマフラー、帽子など LEDテープの準備 まず、どこをどのように装飾するのかを考えます。 LEDテープは33個までに収めてください。 次に、必要な長さにカットします。 そして各端子に導線をはんだ付けして準備完了です。 プログラミング IchigoJamにプログラミングしていきます。 まず、SAVE0にあるプログラムを退避させてください。 WS.LED {数1}コマンドは、配列を最初から参照し、３つずつ読み取ってその３つの値をred、green、blueと認識して、光らせていきます。 一番単純な、全部のLEDをランダムに光らせるプログラムはこれです 1 @ARUN 10 FORI=0TO29:[I]=RND(100):NEXT:WS.LED10:WAIT10:CONT SAVE0して保存してください。 他にも、自分でいろいろ試してみてください。 接続 IchigoJam側の端子と、LEDテープ側の端子を接続していきます。 IchigoJam側 LEDテープ側 GND GND 5V VCC LED DO 上を参考に配線してみてください。 この状態で、IchigoJamの電源を入れると動き出します。 プログラムの最初に「@ARUN」という記述をしてSAVE0に保存すると、起動時に自動実行されるからです。(IchigoJam 1.4の新機能) 持ち運べるようにするには、モバイルバッテリーをつなげるか、乾電池の＋をIchigoJamの5Vに、ーをIchigoJamのGNDにさしてください。 完成 僕たちは、ネックウォーマーや帽子にLEDをつけて遊びました！ プログラムの設定で、かなり明るくなるようにしてあるので、結構まぶしいです。 そのあたりは、自分で試して変更してください。 このキラキラアクセサリーで、パーティーなどを盛り上げよう！]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://koshiscience.github.io/pages/koshiscience/img/2020-08-12-led_handspinner.jpg" /><media:content medium="image" url="https://koshiscience.github.io/pages/koshiscience/img/2020-08-12-led_handspinner.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">はじめまして！</title><link href="https://koshiscience.github.io/pages/koshiscience/2020/03/26/first.html" rel="alternate" type="text/html" title="はじめまして！" /><published>2020-03-26T00:00:00+00:00</published><updated>2020-03-26T00:00:00+00:00</updated><id>https://koshiscience.github.io/pages/koshiscience/2020/03/26/first</id><content type="html" xml:base="https://koshiscience.github.io/pages/koshiscience/2020/03/26/first.html"><![CDATA[<h1 id="はじめまして">はじめまして！</h1>
<p>こんにちは。</p>

<p>福井県立高志中学校サイエンス部です。</p>

<p>この度は、高志中学校サイエンス部のサイトを公開させていただくこととなりました。</p>

<h2 id="サイエンス部について">サイエンス部について</h2>
<p>サイエンス部は、面白そうなことや気になることなどについて、研究したり制作したりしている部活です。</p>

<h2 id="公開に至る経緯">公開に至る経緯</h2>
<p>サイエンス部の中に、今年からできた、IchigoJamなどをメインに行っている「IchigoJamチーム」があるのですが、<a href="https://fukuno.jig.jp">福野さん</a>に「サイエンス部で記事を書いて公開してみたらどう？」というアドバイスを頂いたので、このサイトを開設させていただきました。</p>

<h2 id="今のサイエンス部のチーム">今のサイエンス部のチーム</h2>
<ul>
  <li>IchigoJamチーム
    <ul>
      <li>前述のとおり、IchigoJamをメインに行っているチームですが、プログラミングや電子工作関連には何でも手を出しています。</li>
      <li>大事にしてるのは、面白そうなことをやってみよう！です</li>
    </ul>
  </li>
  <li>缶サット(cansat)チーム
    <ul>
      <li>空き缶サイズの模擬人工衛星、缶サットについての研究・制作を行っています。</li>
      <li>今年は缶サット甲子園出場を目指します！</li>
    </ul>
  </li>
  <li>シャー芯フィラメントチーム
    <ul>
      <li>シャープペンシルの芯に電気を通して、発光させる研究・実験をしています。</li>
      <li>目指せ、10分以上発光！</li>
    </ul>
  </li>
</ul>

<p>今後とも、僕たちサイエンス部の応援をよろしくお願いします！</p>]]></content><author><name></name></author><category term="science-club" /><summary type="html"><![CDATA[はじめまして！ こんにちは。 福井県立高志中学校サイエンス部です。 この度は、高志中学校サイエンス部のサイトを公開させていただくこととなりました。 サイエンス部について サイエンス部は、面白そうなことや気になることなどについて、研究したり制作したりしている部活です。 公開に至る経緯 サイエンス部の中に、今年からできた、IchigoJamなどをメインに行っている「IchigoJamチーム」があるのですが、福野さんに「サイエンス部で記事を書いて公開してみたらどう？」というアドバイスを頂いたので、このサイトを開設させていただきました。 今のサイエンス部のチーム IchigoJamチーム 前述のとおり、IchigoJamをメインに行っているチームですが、プログラミングや電子工作関連には何でも手を出しています。 大事にしてるのは、面白そうなことをやってみよう！です 缶サット(cansat)チーム 空き缶サイズの模擬人工衛星、缶サットについての研究・制作を行っています。 今年は缶サット甲子園出場を目指します！ シャー芯フィラメントチーム シャープペンシルの芯に電気を通して、発光させる研究・実験をしています。 目指せ、10分以上発光！ 今後とも、僕たちサイエンス部の応援をよろしくお願いします！]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://koshiscience.github.io/pages/koshiscience/img/2020-01-27-koshischool.jpg" /><media:content medium="image" url="https://koshiscience.github.io/pages/koshiscience/img/2020-01-27-koshischool.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>